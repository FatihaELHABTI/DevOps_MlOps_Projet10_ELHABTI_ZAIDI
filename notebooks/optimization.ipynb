{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55f75cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 17:54:41.141455: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-08 17:54:41.381168: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-08 17:54:41.581215: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1765212881.745917   13879 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1765212881.793713   13879 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-12-08 17:54:42.220353: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.0\n",
      "GPU disponible ? []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1765212890.715832   13879 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "#imports et configuration\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "# Vérification que tout va bien\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU disponible ?\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Chemins des dossiers\n",
    "DATA_DIR = \"../data/calibration\"  # Vos 170 images\n",
    "MODELS_DIR = \"../models\"          # Où on va sauvegarder\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9903301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargement vers : /home/viet/projet-10-edge-vision/data/tf_cache\n",
      "Downloading data from http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
      "\u001b[1m20515344/20515344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
      "\n",
      "✅ SUCCÈS ! Modèle trouvé ici :\n",
      "/home/viet/projet-10-edge-vision/data/tf_cache/ssd_mobilenet_v2_extracted/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model\n",
      "Contenu : ['saved_model.pb', 'variables']\n"
     ]
    }
   ],
   "source": [
    "#Téléchargement du Modèle Géant (SSD MobileNet V2)\n",
    "import glob\n",
    "\n",
    "# 1. On définit un dossier de cache ABSOLU (pas de \"..\")\n",
    "# On le met dans le dossier 'data' de votre projet\n",
    "cache_dir = os.path.abspath(\"../data/tf_cache\")\n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Téléchargement vers : {cache_dir}\")\n",
    "\n",
    "model_url = \"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\"\n",
    "\n",
    "# 2. Téléchargement\n",
    "# Keras va extraire les fichiers ici\n",
    "path_to_tar = tf.keras.utils.get_file(\n",
    "    fname=\"ssd_mobilenet_v2.tar.gz\",\n",
    "    origin=model_url,\n",
    "    untar=True,\n",
    "    cache_dir=cache_dir,\n",
    "    cache_subdir=\".\" # On extrait directement dans tf_cache\n",
    ")\n",
    "\n",
    "# 3. RECHERCHE AUTOMATIQUE\n",
    "# On ne devine pas le nom, on demande à Python de trouver le dossier \"saved_model\"\n",
    "# qui se trouve quelque part dans cache_dir\n",
    "found_paths = glob.glob(os.path.join(cache_dir, \"**\", \"saved_model\"), recursive=True)\n",
    "\n",
    "if found_paths:\n",
    "    # On prend le premier qu'on trouve\n",
    "    saved_model_path = found_paths[0]\n",
    "    print(f\"\\n✅ SUCCÈS ! Modèle trouvé ici :\")\n",
    "    print(saved_model_path)\n",
    "    \n",
    "    # Vérification du contenu (on doit voir saved_model.pb)\n",
    "    print(\"Contenu :\", os.listdir(saved_model_path))\n",
    "else:\n",
    "    print(\"\\n❌ ERREUR CRITIQUE : Impossible de trouver le dossier 'saved_model' après extraction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "440d918a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1765213406.315246   13879 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1765213406.315330   13879 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2025-12-08 18:03:26.316662: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /home/viet/projet-10-edge-vision/data/tf_cache/ssd_mobilenet_v2_extracted/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model\n",
      "2025-12-08 18:03:26.365018: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-12-08 18:03:26.365051: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /home/viet/projet-10-edge-vision/data/tf_cache/ssd_mobilenet_v2_extracted/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model\n",
      "I0000 00:00:1765213406.739812   13879 mlir_graph_optimization_pass.cc:401] MLIR V1 optimization pass is not enabled\n",
      "2025-12-08 18:03:26.772439: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-12-08 18:03:27.617827: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /home/viet/projet-10-edge-vision/data/tf_cache/ssd_mobilenet_v2_extracted/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model\n",
      "2025-12-08 18:03:28.131590: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 1814932 microseconds.\n",
      "2025-12-08 18:03:28.900132: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle Float32 sauvegardé : ../models/model_float32.tflite\n",
      "Taille : 11.68 MB\n"
     ]
    }
   ],
   "source": [
    "#Conversion \"Classique\" (Float32)\n",
    "# 1. Convertir en TFLite standard (Float32)\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_path)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Sauvegarder\n",
    "float_model_path = os.path.join(MODELS_DIR, \"model_float32.tflite\")\n",
    "with open(float_model_path, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"Modèle Float32 sauvegardé : {float_model_path}\")\n",
    "print(f\"Taille : {len(tflite_model) / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd14c278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Générateur de dataset prêt (Mode UINT8) !\n"
     ]
    }
   ],
   "source": [
    "#Préparation images pour la Calibration (Crucial !)\n",
    "def representative_dataset():\n",
    "    files = os.listdir(DATA_DIR)\n",
    "    \n",
    "    # On prend 100 images\n",
    "    for file_name in files[:100]:\n",
    "        img_path = os.path.join(DATA_DIR, file_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        \n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (320, 320))\n",
    "            \n",
    "            # --- CORRECTION ICI ---\n",
    "            # On garde le format UINT8 (Entiers de 0 à 255)\n",
    "            # Au lieu de convertir en Float32\n",
    "            input_data = np.expand_dims(img, axis=0).astype(np.uint8)\n",
    "            \n",
    "            yield [input_data]\n",
    "            \n",
    "print(\"✅ Générateur de dataset prêt (Mode UINT8) !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe306f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1765213784.069534   13879 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1765213784.069610   13879 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2025-12-08 18:09:44.069794: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /home/viet/projet-10-edge-vision/data/tf_cache/ssd_mobilenet_v2_extracted/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model\n",
      "2025-12-08 18:09:44.110955: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-12-08 18:09:44.110987: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /home/viet/projet-10-edge-vision/data/tf_cache/ssd_mobilenet_v2_extracted/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model\n",
      "2025-12-08 18:09:44.436794: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-12-08 18:09:45.180051: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /home/viet/projet-10-edge-vision/data/tf_cache/ssd_mobilenet_v2_extracted/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model\n",
      "2025-12-08 18:09:45.669077: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 1599286 microseconds.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle Int8 sauvegardé : ../models/model_int8.tflite\n",
      "Taille : 4.07 MB\n"
     ]
    }
   ],
   "source": [
    "#La Conversion \"Optimisée\" (Int8 Quantization)\n",
    "# Recharger le convertisseur\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_path)\n",
    "\n",
    "# --- ACTIVATION DES OPTIMISATIONS ---\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# On lui donne vos images pour qu'il apprenne l'échelle des valeurs\n",
    "converter.representative_dataset = representative_dataset\n",
    "\n",
    "# On force les opérations en entiers (Int8) là où c'est possible\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "\n",
    "# On force aussi les entrées/sorties en entiers (Full Integer Quantization)\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "try:\n",
    "    tflite_quant_model = converter.convert()\n",
    "    \n",
    "    # Sauvegarder\n",
    "    quant_model_path = os.path.join(MODELS_DIR, \"model_int8.tflite\")\n",
    "    with open(quant_model_path, 'wb') as f:\n",
    "        f.write(tflite_quant_model)\n",
    "\n",
    "    print(f\"Modèle Int8 sauvegardé : {quant_model_path}\")\n",
    "    print(f\"Taille : {len(tflite_quant_model) / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Erreur pendant la quantification :\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6a9828b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viet/projet-10-edge-vision/venv/lib/python3.12/site-packages/mlflow/utils/requirements_utils.py:20: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources  # noqa: TID251\n",
      "2025/12/08 18:14:59 INFO mlflow.tracking.fluent: Experiment with name 'Projet_10_Edge_Optimization' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Modèles et métriques envoyés à MLflow !\n"
     ]
    }
   ],
   "source": [
    "#Officialiser dans MLflow\n",
    "import mlflow\n",
    "\n",
    "# On définit le nom de l'expérience\n",
    "mlflow.set_experiment(\"Projet_10_Edge_Optimization\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"MobileNetV2_Quantization\"):\n",
    "    # 1. On enregistre les métriques (La preuve que ça marche)\n",
    "    mlflow.log_metric(\"size_float32_mb\", 11.68)\n",
    "    mlflow.log_metric(\"size_int8_mb\", 4.07)\n",
    "    mlflow.log_metric(\"compression_ratio\", 11.68 / 4.07)\n",
    "    \n",
    "    # 2. On sauvegarde les fichiers modèles DANS MLflow (Le Registry)\n",
    "    mlflow.log_artifact(float_model_path, artifact_path=\"models\")\n",
    "    mlflow.log_artifact(quant_model_path, artifact_path=\"models\")\n",
    "    \n",
    "    print(\"✅ Modèles et métriques envoyés à MLflow !\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
