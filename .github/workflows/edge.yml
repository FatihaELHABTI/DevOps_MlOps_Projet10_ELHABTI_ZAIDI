name: MLOps Edge AI - Real TFLite Models Dashboard

on:
  push:
    branches: [ feature/add ]
  pull_request:
    branches: [ feature/add ]
  workflow_dispatch:

env:
  MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
  PYTHON_VERSION: "3.11"
  DVC_REMOTE_NAME: "vdrive"

jobs:
  setup-and-data:
    name: 1. Data & Environment Setup
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: pip

      - name: Install DVC
        run: pip install "dvc[gdrive]==3.41.0"

      - name: Pull Models from DVC
        env:
          GDRIVE_CREDENTIALS: ${{ secrets.GDRIVE_CREDENTIALS_JSON }}
        run: |
          mkdir -p ~/.dvc
          echo "$GDRIVE_CREDENTIALS" > ~/.dvc/gdrive_service_account.json
          dvc remote modify --local ${{ env.DVC_REMOTE_NAME }} gdrive_use_service_account true
          dvc remote modify --local ${{ env.DVC_REMOTE_NAME }} gdrive_service_account_json_file_path ~/.dvc/gdrive_service_account.json
          dvc pull models.dvc || echo "DVC pull failed, continuing..."

      - name: Upload Models
        uses: actions/upload-artifact@v4
        with:
          name: edge-models
          path: models/

  benchmark-x86-fp32:
    name: 2. x86 Cloud - FP32
    needs: setup-and-data
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/download-artifact@v4
        with:
          name: edge-models
          path: models/
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      - name: Install Dependencies
        run: |
          pip install "numpy<2" psutil
          pip install tflite-runtime
      - name: Run Benchmark
        run: |
          mkdir -p results
          python benchmark.py \
            --output results/x86_fp32.json \
            --device "x86 Cloud" \
            --precision fp32
      - uses: actions/upload-artifact@v4
        with:
          name: x86-fp32-results
          path: results/x86_fp32.json

  benchmark-x86-int8:
    name: 3. x86 Cloud - INT8
    needs: setup-and-data
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/download-artifact@v4
        with:
          name: edge-models
          path: models/
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      - name: Install Dependencies
        run: |
          pip install "numpy<2" psutil
          pip install tflite-runtime
      - name: Run Benchmark
        run: |
          mkdir -p results
          python benchmark.py \
            --output results/x86_int8.json \
            --device "x86 Cloud" \
            --precision int8
      - uses: actions/upload-artifact@v4
        with:
          name: x86-int8-results
          path: results/x86_int8.json

  benchmark-arm64-int8:
    name: 4. ARM64 Edge - INT8 (Native)
    needs: setup-and-data
    runs-on: ubuntu-24.04-arm
    steps:
      - uses: actions/checkout@v4
      - uses: actions/download-artifact@v4
        with:
          name: edge-models
          path: models/
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      - name: Install Dependencies
        run: |
          pip install "numpy<2" psutil
          pip install tflite-runtime
      - name: Run Benchmark
        run: |
          mkdir -p results
          python benchmark.py \
            --output results/arm64_int8.json \
            --device "ARM64 Edge" \
            --precision int8
      - uses: actions/upload-artifact@v4
        with:
          name: arm64-int8-results
          path: results/arm64_int8.json

  reporting:
    name: 5. Real Performance Dashboard
    needs:
      - benchmark-x86-fp32
      - benchmark-x86-int8
      - benchmark-arm64-int8
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      - name: Install Dependencies
        run: pip install matplotlib pandas
      - name: Download All Results
        uses: actions/download-artifact@v4
        with:
          path: all-results/
      - name: Generate Report & Chart
        run: |
          mkdir -p scripts
          cat <<'EOF' > scripts/generate_report.py
          import json
          import pandas as pd
          import matplotlib.pyplot as plt
          from pathlib import Path
          from datetime import datetime

          def load(path):
              with open(path) as f:
                  return json.load(f)

          fp32 = load("all-results/x86-fp32-results/x86_fp32.json")
          x86i = load("all-results/x86-int8-results/x86_int8.json")
          armi = load("all-results/arm64-int8-results/arm64_int8.json")

          df = pd.DataFrame({
              "x86 FP32": [fp32["avg_latency_ms"], fp32["fps"], fp32["model_size_mb"], fp32["peak_memory_mb"]],
              "x86 INT8": [x86i["avg_latency_ms"], x86i["fps"], x86i["model_size_mb"], x86i["peak_memory_mb"]],
              "ARM64 INT8": [armi["avg_latency_ms"], armi["fps"], armi["model_size_mb"], armi["peak_memory_mb"]],
          }, index=["Latency (ms)", "FPS", "Model Size (MB)", "Peak Memory (MB)"])

          ax = df.plot(kind="bar", figsize=(14,8))
          ax.set_title("Real TFLite Edge AI Performance")
          plt.tight_layout()
          plt.savefig("performance_comparison.png", dpi=150)

          report = f"""# Real Edge AI Performance Dashboard ({datetime.now().date()})

          | Metric | x86 FP32 | x86 INT8 | ARM64 INT8 |
          |-------|---------|----------|------------|
          | Latency (ms) | {fp32['avg_latency_ms']:.2f} | {x86i['avg_latency_ms']:.2f} | {armi['avg_latency_ms']:.2f} |
          | FPS | {fp32['fps']:.1f} | {x86i['fps']:.1f} | {armi['fps']:.1f} |
          | Model Size (MB) | {fp32['model_size_mb']:.1f} | {x86i['model_size_mb']:.1f} | {armi['model_size_mb']:.1f} |
          | Peak Memory (MB) | {fp32['peak_memory_mb']:.1f} | {x86i['peak_memory_mb']:.1f} | {armi['peak_memory_mb']:.1f} |
          """

          Path("final_report.md").write_text(report)
          EOF
          python scripts/generate_report.py
      - name: Publish to Job Summary
        run: cat final_report.md >> $GITHUB_STEP_SUMMARY
      - name: Upload Dashboard
        uses: actions/upload-artifact@v4
        with:
          name: performance-dashboard
          path: |
            performance_comparison.png
            final_report.md